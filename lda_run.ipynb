{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda2\\lib\\site-packages\\gensim\\utils.py:855: UserWarning: detected Windows; aliasing chunkize to chunkize_serial\n",
      "  warnings.warn(\"detected Windows; aliasing chunkize to chunkize_serial\")\n"
     ]
    }
   ],
   "source": [
    "import gensim\n",
    "from gensim import corpora\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('cleaned_article.json', 'r') as f:\n",
    "     data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2246"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = filter(None, data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for i, article in enumerate (data):\n",
    "    data[i] = [s.encode('utf-8') for s in article] # decode unicode str to str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dictionary = corpora.Dictionary(data)\n",
    "# Represents entire corpus in bag-of-words format i.e list of\n",
    " # (id, count) tuples\n",
    "doc_term_matrix = [dictionary.doc2bow(doc) for doc in data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "    # Create variable to store LDA class\n",
    "Lda = gensim.models.ldamodel.LdaModel \n",
    "    # Initialize LDA object; estimates LDA model parameters on \n",
    "    # corpus in bag-of-words format \n",
    "ldamodel = Lda(doc_term_matrix, num_topics=10, id2word=dictionary, passes=50, minimum_probability = 0.0001) # lower probability threshold for more precise prediction\n",
    "    # Save model\n",
    "ldamodel.save('10ap.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------- Word distribution for each topic -----------\n",
      "['water', 'area', 'county', 'national', 'people', 'city', 'state', 'year', 'fire', 'mile', 'venus', 'nordstrom', 'space', 'galileo', 'river', 'high', 'ohio', 'company', 'police', 'department']\n",
      "['year', 'percent', 'bill', 'tax', 'money', 'committee', 'program', 'defense', 'state', 'federal', 'fund', 'budget', 'month', 'government', 'fiscal', 'work', 'health', 'law', 'public', 'campaign']\n",
      "['south', 'school', 'africa', 'people', 'student', 'year', 'black', 'african', 'percent', 'virus', 'mandela', 'group', 'report', 'computer', 'state', 'system', 'release', 'time', 'day', 'official']\n",
      "['government', 'official', 'us', 'president', 'year', 'child', 'party', 'military', 'time', 'panama', 'country', 'people', 'human', 'china', 'force', 'union', 'american', 'tuesday', 'bank', 'month']\n",
      "['court', 'attorney', 'case', 'trial', 'judge', 'charge', 'us', 'law', 'united', 'states', 'general', 'federal', 'document', 'dress', 'jury', 'drug', 'government', 'prison', 'told', 'investigation']\n",
      "['percent', 'market', 'year', 'price', 'trade', 'us', 'united', 'rate', 'dollar', 'stock', 'states', 'economic', 'sale', 'agreement', 'country', 'cent', 'government', 'economy', 'nation', 'japan']\n",
      "['police', 'people', 'official', 'day', 'city', 'year', 'us', 'killed', 'state', 'today', 'iraq', 'force', 'death', 'time', 'man', 'officer', 'government', 'country', 'group', 'attack']\n",
      "['company', 'air', 'plane', 'ship', 'offer', 'share', 'bank', 'black', 'inc', 'force', 'employee', 'service', 'macmillan', 'firm', 'week', 'maxwell', 'office', 'cdy', 'navy', 'saudi']\n",
      "['year', 'company', 'book', 'york', 'american', 'estate', 't', 'ruby', 'computer', 'airline', 'time', 'film', 'robert', 'john', 'dump', 'flight', 'plant', 'monday', 'firm', 'apple']\n",
      "['bush', 'president', 'soviet', 'state', 'party', 'dukakis', 'vote', 'percent', 'leader', 'campaign', 'democratic', 'people', 'union', 'election', 'poll', 'political', 'year', 'support', 'east', 'candidate']\n"
     ]
    }
   ],
   "source": [
    "# Print word distribution (top words only) of each topic\n",
    "print(\"----------- Word distribution for each topic -----------\")\n",
    "topics = ldamodel.print_topics(num_topics=10, num_words=20)\n",
    "for topic in topics:\n",
    "    dist = [item.split(\"*\\\"\")[1][:-1].encode(\"utf8\") for item in topic[1].split(\" + \")]\n",
    "    print(dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "result = []\n",
    "for i in range(len(data[:10])):\n",
    "    article = dict((x,y) for x,y in ldamodel[dictionary.doc2bow(data[:10][i])])\n",
    "    for h in range (0, 10):\n",
    "        if h not in article.keys():\n",
    "            article[h] = 0\n",
    "    result.append(article)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{0: 0.00037885144884944007,\n",
       "  1: 0.00037886674911592787,\n",
       "  2: 0.15118729702940722,\n",
       "  3: 0.00037885438177925489,\n",
       "  4: 0.0075547909027124261,\n",
       "  5: 0.00037885257873212694,\n",
       "  6: 0.79810822555647898,\n",
       "  7: 0.00037883473494782237,\n",
       "  8: 0.040876520351527758,\n",
       "  9: 0.00037890626644917981},\n",
       " {0: 0.00038469630523947716,\n",
       "  1: 0.00038473254378890712,\n",
       "  2: 0.0003846737339858172,\n",
       "  3: 0.11800092146610167,\n",
       "  4: 0.26970083991083915,\n",
       "  5: 0.066224501594359775,\n",
       "  6: 0.14180447679078889,\n",
       "  7: 0.12230333976804572,\n",
       "  8: 0.23373947963142705,\n",
       "  9: 0.047072338255423521},\n",
       " {0: 0.029127816617169209,\n",
       "  1: 0.027839876603177556,\n",
       "  2: 0.016506793722749578,\n",
       "  3: 0.00043488657489497374,\n",
       "  4: 0.2918822088697256,\n",
       "  5: 0.00043487195840120885,\n",
       "  6: 0.44628603227335389,\n",
       "  7: 0.00043490917822858486,\n",
       "  8: 0.18661775719017409,\n",
       "  9: 0.00043484701212517232},\n",
       " {0: 0.00043490068934013657,\n",
       "  1: 0.0004348986624472305,\n",
       "  2: 0.048417980924407286,\n",
       "  3: 0.00043489606543127465,\n",
       "  4: 0.00043496069855696371,\n",
       "  5: 0.080549433534952072,\n",
       "  6: 0.49522595384405804,\n",
       "  7: 0.055891432903397348,\n",
       "  8: 0.12522762725697231,\n",
       "  9: 0.19294791542043729},\n",
       " {0: 0.0013166379998830204,\n",
       "  1: 0.0013162296321502485,\n",
       "  2: 0.0013163842457288469,\n",
       "  3: 0.0013163784384703095,\n",
       "  4: 0.0013167764446554307,\n",
       "  5: 0.0013160089578277249,\n",
       "  6: 0.80641552344935452,\n",
       "  7: 0.0013159266196489051,\n",
       "  8: 0.0013163306804666801,\n",
       "  9: 0.18305380353181427},\n",
       " {0: 0.00024218069229974343,\n",
       "  1: 0.066091681748811651,\n",
       "  2: 0.00024219688283852819,\n",
       "  3: 0.41998405635256308,\n",
       "  4: 0.0154579312700801,\n",
       "  5: 0.045139072843912886,\n",
       "  6: 0.16650239917887757,\n",
       "  7: 0.00024222939406225475,\n",
       "  8: 0.00024219555282811779,\n",
       "  9: 0.28585605608372616},\n",
       " {0: 0.00060626012480635228,\n",
       "  1: 0.017350062862472333,\n",
       "  2: 0.00060620756424084523,\n",
       "  3: 0.34526922031328483,\n",
       "  4: 0.051104794085369241,\n",
       "  5: 0.26252495828494993,\n",
       "  6: 0.14134235361458056,\n",
       "  7: 0.048668699208520724,\n",
       "  8: 0.11759075713137852,\n",
       "  9: 0.014936686810396747},\n",
       " {0: 0.0017858554649280839,\n",
       "  1: 0.0017860655119277594,\n",
       "  2: 0.0017865708059661709,\n",
       "  3: 0.0017859442070935383,\n",
       "  4: 0.0017858513063510771,\n",
       "  5: 0.024125903859136166,\n",
       "  6: 0.0017861218356643705,\n",
       "  7: 0.0017857967972745143,\n",
       "  8: 0.0017858265307581717,\n",
       "  9: 0.96158606368090016},\n",
       " {0: 0.58943128328217587,\n",
       "  1: 0.012502059278339918,\n",
       "  2: 0.012500797903095636,\n",
       "  3: 0.012504617189177699,\n",
       "  4: 0.012500695165412549,\n",
       "  5: 0.01250262852765369,\n",
       "  6: 0.012501728491078296,\n",
       "  7: 0.31055202293915446,\n",
       "  8: 0.012501266749680183,\n",
       "  9: 0.01250290047423166},\n",
       " {0: 0.0007754486809936975,\n",
       "  1: 0.00077532521672552879,\n",
       "  2: 0.00077549914001350277,\n",
       "  3: 0.00077532116771022021,\n",
       "  4: 0.00077542178804186775,\n",
       "  5: 0.21628037482785123,\n",
       "  6: 0.21575657714313201,\n",
       "  7: 0.00077527775457660595,\n",
       "  8: 0.10754171683504635,\n",
       "  9: 0.45576903744590908}]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------- Word distribution for each topic -----------\n",
      "{'water': '0.006', 'county': '0.005', 'national': '0.005', 'people': '0.005', 'area': '0.006'}\n",
      "{'money': '0.006', 'tax': '0.006', 'bill': '0.007', 'percent': '0.008', 'year': '0.015'}\n",
      "{'school': '0.008', 'africa': '0.008', 'student': '0.006', 'south': '0.009', 'people': '0.006'}\n",
      "{'president': '0.006', 'official': '0.007', 'year': '0.005', 'us': '0.007', 'government': '0.012'}\n",
      "{'case': '0.010', 'trial': '0.009', 'attorney': '0.012', 'court': '0.014', 'judge': '0.009'}\n",
      "{'price': '0.008', 'trade': '0.007', 'percent': '0.013', 'market': '0.009', 'year': '0.009'}\n",
      "{'city': '0.004', 'official': '0.005', 'police': '0.010', 'day': '0.004', 'people': '0.007'}\n",
      "{'company': '0.008', 'plane': '0.006', 'offer': '0.005', 'ship': '0.005', 'air': '0.006'}\n",
      "{'american': '0.003', 'company': '0.005', 'book': '0.004', 'york': '0.004', 'year': '0.007'}\n",
      "{'president': '0.009', 'bush': '0.013', 'soviet': '0.008', 'state': '0.007', 'party': '0.007'}\n"
     ]
    }
   ],
   "source": [
    "# Print word distribution (top words only) and correspondence percentage of each topic\n",
    "print(\"----------- Word distribution for each topic -----------\")\n",
    "topics = ldamodel.print_topics(num_topics=10, num_words=5)\n",
    "for topic in topics:\n",
    "    dist = dict((item.split(\"*\\\"\")[1][:-1].encode(\"utf8\"),item.split(\"*\\\"\")[0].encode(\"utf8\"))  for item in topic[1].split(\" + \"))\n",
    "    print(dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
